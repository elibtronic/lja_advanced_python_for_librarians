{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdv0eMPmoMz71auTUIirTB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Week 3 - Text Analysis & Working with Text Files\n",
        "\n",
        "(Be sure to copy to drive)\n",
        "\n",
        "Text data is a bit different from numeric data. We can easily find the average of a series of numbers and things like the highest and lowest values in a range to get some ideas on what we are dealing with. We can't really do that with text. We'll focus on some tools that you can use to actually analyze text. We'll start with a library called [TextBlob](https://textblob.readthedocs.io/en/dev/)."
      ],
      "metadata": {
        "id": "fk-Vimof6JCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load up our libraries\n",
        "from textblob import TextBlob\n",
        "from google.colab import drive\n",
        "\n",
        "#these should look familar\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import requests\n",
        "\n",
        "#Some extra libraries we'll need for text analysis\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "#Connect to Gdrive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "print(\"Libraries and Drive Ready!\")"
      ],
      "metadata": {
        "id": "MI5KZIg-sATg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A text dataset\n",
        "\n",
        "We are going to use a digial humanities example to explore some things that are possible. We'll begin with a diary from a young girl from the year 1901. Her name is Winnie Beam. Her [diary](http://hdl.handle.net/10464/7282) has been digitized, as well as turned into [data](https://docs.google.com/spreadsheets/d/17FO_a6jcLgycwDd7uYsrpPqcIterjquY2UyC7QAZmWs/edit?usp=sharing).\n",
        "\n",
        "We are going to read in a CSV version of the data and put it into a dataframe."
      ],
      "metadata": {
        "id": "aTyNmtj_rvOC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run this cell to load up our 'corpus'\n",
        "\n",
        "winnie_corpus = pd.read_csv('https://docs.google.com/spreadsheets/d/e/2PACX-1vQcj2YkYKMn3HZo-5yfKw65kVENg_RZLRTrBxvJeRPB46k0z_BqIUD5ecuoyEmEGuCJ79ZyP-8rGeIv/pub?gid=0&single=true&output=csv', header = None)\n",
        "winnie_corpus.columns = [\"page\",\"date\",\"entry\"]\n",
        "winnie_corpus['date'] = pd.to_datetime(winnie_corpus['date'])\n",
        "winnie_corpus['entry'] = winnie_corpus.entry.astype(str)\n",
        "\n",
        "#preview our top entries\n",
        "winnie_corpus.head()"
      ],
      "metadata": {
        "id": "Bf1ECXOWruN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "\n",
        "We can analyze the _sentiment_ of the text (more [details](https://planspace.org/20150607-textblob_sentiment/).) The next cell demonstrates this:"
      ],
      "metadata": {
        "id": "f3nc9XKRsWOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "happy_sentence = \"Python is the best programming language ever!\"\n",
        "sad_sentence = \"Python is difficult to use, and very frustrating\"\n",
        "\n",
        "\n",
        "print(\"Sentiment of happy sentence \", TextBlob(happy_sentence).sentiment)\n",
        "print(\"Sentiment of sad sentence \", TextBlob(sad_sentence).sentiment)\n",
        "\n",
        "# polarity ranges from -1 to 1.\n",
        "# subjectvity ranges from 0 to 1.\n"
      ],
      "metadata": {
        "id": "L7vh_zzbsZ-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1**  Try a couple of different sentences in the code cell below. See if you can create something that scores -1 and another that scores 1 for polarity. See if you can minimize the subjectivity of your sentence.\n",
        "(We can create a multi line string of text by putting it in triple quotes like the cell following.)\n"
      ],
      "metadata": {
        "id": "cb_OrBposeAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"\"\"\n",
        "\n",
        "Will this be a happy sentence or a sad one? Only TextBlob will tell!\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "print(\"Score of test sentence is \", TextBlob(test_text).sentiment)"
      ],
      "metadata": {
        "id": "1i9tyZCBsjPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Sentiment to our Diary entries\n",
        "\n",
        "This next cell will score each diary entry in a new column that will be added to the dataframe. We loop through each entry, calculate the two scores that represent the sentiment. After all the scores are computed we will add them to the dataframe."
      ],
      "metadata": {
        "id": "7IK_FiGxs0QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply sentiment analysis from TextBlob\n",
        "\n",
        "polarity = []\n",
        "subjectivity = []\n",
        "\n",
        "\n",
        "for day in winnie_corpus.entry:\n",
        "    score = TextBlob(day)\n",
        "    polarity.append(score.sentiment.polarity)\n",
        "    subjectivity.append(score.sentiment.subjectivity)\n",
        "\n",
        "winnie_corpus['polarity'] = polarity\n",
        "winnie_corpus['subjectivity'] = subjectivity\n",
        "\n",
        "\n",
        "#Let's look at our new top entries\n",
        "winnie_corpus.head()"
      ],
      "metadata": {
        "id": "JsEpWdXCs3iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Entries\n",
        "\n",
        "We can now see that scoring has been added. Run the next cell a few times to see different random entries."
      ],
      "metadata": {
        "id": "IP3C25tluhdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "winnie_corpus.sample(5)"
      ],
      "metadata": {
        "id": "1Zisntqouwxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now what?\n",
        "\n",
        "We can do many things with the new data. For now lets just draw a line graph showing the changes in _polarity_ in her dairy entries."
      ],
      "metadata": {
        "id": "Ze0eqGxns99D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's graph out the sentiment as it changes day to day.\n",
        "\n",
        "plt.plot(winnie_corpus[\"date\"],winnie_corpus[\"polarity\"])\n",
        "plt.title(\"Polarity sentiment of Winnie's Diary Entries\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VzePwaDCtSoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2** Modify the following code cell to create a line graph of the _subjectivity_ of her diary entries for the year."
      ],
      "metadata": {
        "id": "CQjN_u4au2SC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(winnie_corpus[\"date\"],winnie_corpus[])\n",
        "plt.title(\"CHANGEME\")\n",
        "plt.ylabel(\"CHANGEME\")\n",
        "plt.xlabel(\"CHANGEME\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0OBEw2uPvSju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Closer look?\n",
        "\n",
        "Let's take a closer look at the really high _polarity_ sentiment entries to see what is going on."
      ],
      "metadata": {
        "id": "t3Cyb6aKt-By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top Five\n",
        "winnie_corpus.sort_values(by = 'polarity', ascending = False).head(5)"
      ],
      "metadata": {
        "id": "jdMxs-5etn5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top Five\n",
        "winnie_corpus.sort_values(by = 'polarity', ascending = True).head(5)"
      ],
      "metadata": {
        "id": "NtZFh8eIuGlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3** Do you agree with the polarity scores that TextBlob assigns to these diary entries? Why or what not? Feel free to add some notes into the following text cell"
      ],
      "metadata": {
        "id": "vruNEF9juKIh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think that the sentiment scoring is..."
      ],
      "metadata": {
        "id": "2vRqJeRUuZhK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noun Phrases\n",
        "\n",
        "\n",
        "We can get a good idea about what a corpus is about by looking at the different nouns that show up in it. Nouns that show up a lot give us an idea of the contents of the text. Textblob can do this for us. Run the cell below a few times to grab random entries in the data and to see what noun phrases they use."
      ],
      "metadata": {
        "id": "TNWoQYE4wAvO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We need a library to get Python to do stuff with Random values\n",
        "import random\n",
        "random_entry_number = random.randint(0,len(winnie_corpus))\n",
        "\n",
        "#We finally pick a random entry here\n",
        "bit_of_corpus = TextBlob(winnie_corpus[\"entry\"][random_entry_number])\n",
        "\n",
        "print(\"page:\",winnie_corpus.iloc[random_entry_number]['page'])\n",
        "print(\"date: \", winnie_corpus.iloc[random_entry_number]['date'])\n",
        "print(\"entry: \\n\", winnie_corpus.iloc[random_entry_number]['entry'])\n",
        "\n",
        "print(\"---\")\n",
        "print(\"Noun Phrases found\")\n",
        "print(\"---\")\n",
        "for np in bit_of_corpus.noun_phrases:\n",
        "    print(np)"
      ],
      "metadata": {
        "id": "UAO9r13UxsBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4** What do you think about the Noun Phrase identification? Is it useful or not?\n",
        "\n"
      ],
      "metadata": {
        "id": "qYV1WKM2zEzt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I think Noun Phrase..."
      ],
      "metadata": {
        "id": "Wk5Z2n8XzXKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Noun Phrases for the Diary\n",
        "\n",
        "Now let's generate the noun phrases for January's entries"
      ],
      "metadata": {
        "id": "UKIChflxzeR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#we use some pandas work to just grab the January entries\n",
        "#stretch back into your memory to think about conditionals again\n",
        "jan_corpus = winnie_corpus[(winnie_corpus['date'] >= '1900-01-01') & (winnie_corpus['date'] <= '1900-01-31')]\n",
        "\n",
        "jan_phrases = dict()\n",
        "\n",
        "for entry in jan_corpus.entry:\n",
        "\n",
        "    tb = TextBlob(entry)\n",
        "    #we create a dictionary that will hold the noun phrases\n",
        "    #if it is the first time we see this np we put it in the dictionary\n",
        "    #if not, we must have a count already, so we increase that by one\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in jan_phrases:\n",
        "            jan_phrases[np] += 1\n",
        "        else:\n",
        "            jan_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in January\n",
        "\n",
        "for np in sorted(jan_phrases, key=jan_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, jan_phrases[np])\n",
        "\n"
      ],
      "metadata": {
        "id": "purfjNiyz5K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5** Modify the next series of cells to generate noun phrases for the next 5 months of the year."
      ],
      "metadata": {
        "id": "QyyiwRtl0YHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#February Entries\n",
        "feb_corpus = winnie_corpus[(winnie_corpus['date'] >= '') & (winnie_corpus['date'] <= '')]\n",
        "\n",
        "feb_phrases = dict()\n",
        "\n",
        "for entry in feb_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in feb_phrases:\n",
        "            feb_phrases[np] += 1\n",
        "        else:\n",
        "            feb_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in February\n",
        "\n",
        "for np in sorted(feb_phrases, key=feb_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, feb_phrases[np])"
      ],
      "metadata": {
        "id": "oQNk7cKk0k58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#March Entries\n",
        "mar_corpus = winnie_corpus[(winnie_corpus['date'] >= '') & (winnie_corpus['date'] <= '')]\n",
        "\n",
        "\n",
        "mar_phrases = dict()\n",
        "\n",
        "for entry in mar_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in mar_phrases:\n",
        "            mar_phrases[np] += 1\n",
        "        else:\n",
        "            mar_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in March\n",
        "\n",
        "for np in sorted(mar_phrases, key=mar_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, mar_phrases[np])"
      ],
      "metadata": {
        "id": "fCYCoxuq0nFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#April Entries\n",
        "april_corpus = winnie_corpus[(winnie_corpus['date'] >= '') & (winnie_corpus['date'] <= '')]\n",
        "\n",
        "april_phrases = dict()\n",
        "\n",
        "for entry in april_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in april_phrases:\n",
        "            april_phrases[np] += 1\n",
        "        else:\n",
        "            april_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in April\n",
        "\n",
        "for np in sorted(april_phrases, key=april_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, april_phrases[np])"
      ],
      "metadata": {
        "id": "WEaes_9a0pjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#May Entries\n",
        "may_corpus = winnie_corpus[(winnie_corpus['date'] >= '') & (winnie_corpus['date'] <= '')]\n",
        "\n",
        "may_phrases = dict()\n",
        "\n",
        "for entry in may_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in may_phrases:\n",
        "            may_phrases[np] += 1\n",
        "        else:\n",
        "            may_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in may\n",
        "\n",
        "for np in sorted(may_phrases, key=may_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, may_phrases[np])"
      ],
      "metadata": {
        "id": "udZAsoL40tT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#June Entries\n",
        "june_corpus = winnie_corpus[(winnie_corpus['date'] >= '') & (winnie_corpus['date'] <= '')]\n",
        "\n",
        "june_phrases = dict()\n",
        "\n",
        "for entry in june_corpus.entry:\n",
        "    tb = TextBlob(entry)\n",
        "    for np in tb.noun_phrases:\n",
        "        if np in june_phrases:\n",
        "            june_phrases[np] += 1\n",
        "        else:\n",
        "            june_phrases[np] = 1\n",
        "\n",
        "#Print the top 10 things she mentioned in june\n",
        "\n",
        "for np in sorted(june_phrases, key=june_phrases.get, reverse=True)[0:10]:\n",
        "    print(np, june_phrases[np])"
      ],
      "metadata": {
        "id": "H5u2HvnF0vuT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Changes in topic\n",
        "\n",
        "\n",
        "**Q6**\n",
        "Take a moment to look at what is printed for each month. Can you get a sense of what Winnie is writing about over the months? Or how those topics change?"
      ],
      "metadata": {
        "id": "hVMKpulb0znO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What I can tell from looking at Noun Phrases in the diary is..."
      ],
      "metadata": {
        "id": "wtrQp86dUYpV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text and Text Files\n",
        "\n",
        "Our week 2 & week 3 warmup material introduced some ideas about working with files in Google Drive and in our Colab environment. Since we are dealing with text analysis right now we'll take a moment to talk about text files as well.\n",
        "\n",
        "Sometimes we want to take a string variable and write it to a file so that we can use it a later time.\n",
        "\n",
        "We'll also make use of automatically grabbing content from the web using the [requests](https://pypi.org/project/requests/) library just like we did in week 1. We are going to grab a book from the [Project Guttenberg](https://www.gutenberg.org/) site as our example.\n",
        "\n",
        "This is technically an example of screen scrapping. IE. we are programmatically grabbing content from the web using an automated tool. This is the type of thing that AI bots are doing and arguably it is [ruining](https://library.unc.edu/news/library-it-vs-the-ai-bots/) the web."
      ],
      "metadata": {
        "id": "ZY6E2Au8ILJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll be using the H.G. Wells book - The Invisible Man (https://www.gutenberg.org/ebooks/5230)\n",
        "#but we'll focus on the plain text version\n",
        "book_text_url = \"https://www.gutenberg.org/cache/epub/5230/pg5230.txt\"\n",
        "\n",
        "response = requests.get(book_text_url)"
      ],
      "metadata": {
        "id": "nuRPCpD5JMbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we now have a string variable (response.text) which holds the whole text of the book\n",
        "response.text"
      ],
      "metadata": {
        "id": "7h9lQz9_LXTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#File I/O in Python is a whole week of content on its own\n",
        "#but quickly, the 'w' means we are writing to the file\n",
        "with (open('invisible_man.txt', 'w')) as f:\n",
        "    f.write(response.text)"
      ],
      "metadata": {
        "id": "yzHT_CW5L2cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Magic command to display contents of folder\n",
        "!ls -l"
      ],
      "metadata": {
        "id": "Hppl87rMMBTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# File I/O? More to go!\n",
        "\n",
        "I'll encourage you to look up more tutorials with working with files in Python to get a full sense of what is possible.\n",
        "\n",
        "Check out your drive through the [web](https://drive.google.com/), navigate to your `LibraryJuicePython` folder and have a look at what is there now."
      ],
      "metadata": {
        "id": "83PwQAuGM8cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# One final activity: Automatic Keyword Generator\n",
        "\n",
        "Let's put all of what we have learned together to create an automatic keyword generator that identifies Noun Phrases in a book from Guttenberg.\n",
        "\n",
        "We are going to be looking at the book [The Prince](https://en.wikipedia.org/wiki/The_Prince)\n"
      ],
      "metadata": {
        "id": "h9T-GaM11d2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = dict()\n",
        "\n",
        "# We are using The Prince - https://www.gutenberg.org/ebooks/1232\n",
        "book_url = \"https://www.gutenberg.org/files/1232/1232-0.txt\"\n",
        "book_title = \"The Prince\"\n",
        "\n",
        "\n",
        "print(\"Downloading book...\")\n",
        "book = requests.get(book_url)\n",
        "\n",
        "#save a copy of the downloaded book as a text file\n",
        "with (open(book_title+'.txt', 'w')) as f:\n",
        "    f.write(book.text)\n",
        "\n",
        "#Turn text into text blob\n",
        "book_blob = TextBlob(book.text)\n",
        "\n",
        "\n",
        "print(\"Identiying Noun phrases and building frequency dictionary...\")\n",
        "\n",
        "#Go through all noun phrases\n",
        "for np in book_blob.noun_phrases:\n",
        "    if np in keywords:\n",
        "        keywords[np] += 1\n",
        "    else:\n",
        "        keywords[np] = 1\n",
        "\n",
        "noun_phrases = \"\"\n",
        "#Sort dictionary and print top 20 entries\n",
        "print(\"Most common Nouns...\")\n",
        "\n",
        "for np in sorted(keywords, key=keywords.get, reverse=True)[0:20]:\n",
        "    noun_phrases += np + \",\"+str(keywords[np])+\"\\n\"\n",
        "    print(np, keywords[np])\n",
        "\n",
        "with(open(book_title+'_keywords.txt','w')) as f:\n",
        "    f.write(noun_phrases)"
      ],
      "metadata": {
        "id": "pCqmXSHk1vSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's look again at what is in our folder\n",
        "!ls"
      ],
      "metadata": {
        "id": "UhEVfkZYObvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's move all of the files we created for this exercise to our usual folder\n",
        "!mv *.txt /content/gdrive/MyDrive/LibraryJuicePython"
      ],
      "metadata": {
        "id": "vMWtVmiRO3Nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7** Trying running the automatic keyword generator on a different book from Guttenberg. Perhaps something you have already read. Do you think it gives you a good idea of what the thing is about?\n",
        "\n",
        "\n",
        "You will need to change the values for `book_url` and `book_title` in line 4 & 5."
      ],
      "metadata": {
        "id": "TF_NbsjA2B_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Moral of the story\n",
        "\n",
        "Text analysis lets you do a bunch of different things. We have just scratched the surface here."
      ],
      "metadata": {
        "id": "-u_4zJ2VU8rv"
      }
    }
  ]
}